{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbc04238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import calendar\n",
    "import math\n",
    "import itertools\n",
    "import datetime\n",
    "import win32com.client as win32\n",
    "#from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "d4d0b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scrapping dates\n",
    "\n",
    "url = \"https://www.ecb.europa.eu/pub/projections/html/all-releases.en.html\"\n",
    "page = urlopen(url)\n",
    "html = page.read().decode(\"utf-8\")\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#Creating dataframe\n",
    "dat = soup.find_all(\"dt\")\n",
    "dats=[0 for i in range((len(dat)))]\n",
    "for i in range(0,len(dat)): \n",
    "    dats[i]=dat[i][\"isodate\"]\n",
    "\n",
    "#removing duplicates, noisy data and reseting index\n",
    "dates = pd.DataFrame(dats, columns=[\"Dates\"]).drop_duplicates()\n",
    "dates = dates.drop(labels=[6,11,16,21,26,31,36,38,41,46,51,56,61,64,67], axis=0).reset_index()\n",
    "dates = dates.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "b72a44c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Completing with missing dates\n",
    "dates.loc[78, \"Dates\"] = '2004-03-04'\n",
    "dates.loc[79, \"Dates\"] = '2003-12-04'\n",
    "dates.loc[80, \"Dates\"] = '2003-09-04'\n",
    "dates.loc[81, \"Dates\"] = '2003-06-05'\n",
    "dates.loc[82, \"Dates\"] = '2003-03-06'\n",
    "dates.loc[83, \"Dates\"] = '2002-12-05'\n",
    "dates.loc[84, \"Dates\"] = '2002-09-05'\n",
    "dates.loc[85, \"Dates\"] = '2002-06-06'\n",
    "dates.loc[86, \"Dates\"] = '2002-03-07'\n",
    "dates.loc[87, \"Dates\"] = '2001-12-06'\n",
    "dates.loc[88, \"Dates\"] = '2001-09-06'\n",
    "dates.loc[89, \"Dates\"] = '2001-06-07'\n",
    "dates.loc[90, \"Dates\"] = '2001-03-01'\n",
    "dates.loc[91, \"Dates\"] = '2000-12-07'\n",
    "dates.loc[92, \"Dates\"] = '2000-09-07'\n",
    "dates.loc[93, \"Dates\"] = '2000-06-01'\n",
    "dates.loc[94, \"Dates\"] = '2000-03-02'\n",
    "dates.loc[95, \"Dates\"] = '1999-12-02'\n",
    "dates.loc[96, \"Dates\"] = '1999-09-02'\n",
    "dates.loc[97, \"Dates\"] = '1999-06-03'\n",
    "dates.loc[98, \"Dates\"] = '1999-03-04'\n",
    "\n",
    "#Converting to datetype and subtracting the three weeks\n",
    "dates[\"Dates\"] = pd.to_datetime(dates[\"Dates\"])-datetime.timedelta(days=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "2fcc1321",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\ECB projections\\\\\"\n",
    "\n",
    "spring = dates[dates['Dates'].dt.month == (5 or 6)].iloc[::-1]\n",
    "spring.to_csv(path1+'spring.csv')\n",
    "\n",
    "summer = dates[dates['Dates'].dt.month == (8 or 9)].iloc[::-1]\n",
    "summer.to_csv(path1+'summer.csv')\n",
    "\n",
    "winter = dates[dates['Dates'].dt.month == (2 or 3)].iloc[::-1]\n",
    "winter.to_csv(path1+'winter.csv')\n",
    "\n",
    "autumn = dates[dates['Dates'].dt.month == (11 or 12)].iloc[::-1]\n",
    "autumn.to_csv(path1+'autumn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730331d",
   "metadata": {},
   "source": [
    "# From Here it is another part of the code, do not run the above again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019e1350",
   "metadata": {},
   "source": [
    "Create find closest date here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1482c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and adjusting data\n",
    "path1 = \"G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\ECB projections\\\\\"\n",
    "\n",
    "for var in ['RealGDP', 'HCIP']:\n",
    "\n",
    "    # Print the resulting DataFrame\n",
    "    csvfile_path = path1 + f\"{var}.csv\"\n",
    "    csvfile=pd.read_csv(csvfile_path, header=0, skiprows = lambda x: x in range(6))\n",
    "    csvfile['Dates']=pd.to_datetime(csvfile['Dates'], format=\"%d/%m/%Y\")\n",
    "\n",
    "    #Splitting column string name '2014-Q1' into '2014' and '1'\n",
    "    listy = csvfile.columns[2:].str.split('-Q', expand=True)\n",
    "\n",
    "    #Rebuilding names swiotiching back to 'Q1 2014' via list comprehension\n",
    "    kappa = ['Q'+listy[a][1] + ' ' + listy[a][0] for a in range(len(csvfile.columns)-2) ]\n",
    "\n",
    "    #Creating dictionary to rename the dataframe\n",
    "    almir = dict(zip(csvfile.columns[2:], kappa))\n",
    "\n",
    "    #Renaming the dataframe\n",
    "    csvfile.rename(columns= almir , inplace = True)\n",
    "    if var == 'RealGDP':\n",
    "        rdp = csvfile\n",
    "\n",
    "    elif var == 'HCIP':\n",
    "        cip = csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21ad7f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile_path = path1 + \"Unemp.csv\"\n",
    "csvfile=pd.read_csv(csvfile_path, header=0, skiprows = lambda x: x in range(6))\n",
    "csvfile['Dates']=pd.to_datetime(csvfile['Dates'], format=\"%d/%m/%Y\")\n",
    "\n",
    "unemp = csvfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "412c063c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Building dataset to run regressions\n",
    "\n",
    "# Read the reference dates from source1.xlsx\n",
    "source_file = 'G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\Instrument\\\\Dataset_EA-MPD.xlsx'\n",
    "df_source = pd.read_excel(source_file, header=0, sheet_name=1)\n",
    "\n",
    "# Get the reference dates from the first column\n",
    "reference_dates = df_source.iloc[:, 0]\n",
    "\n",
    "# Create a DataFrame with the reference dates\n",
    "result_df = pd.DataFrame(data=reference_dates)\n",
    "\n",
    "# Add the quarter column\n",
    "result_df['Quarter'] = pd.PeriodIndex(result_df['date'], freq='Q')\n",
    "\n",
    "# Read the comp.csv file and get the fourth column\n",
    "#csv_file = 'comp.csv'\n",
    "#df_csv = pd.read_csv(csv_file, header=None)\n",
    "#fourth_column = df_csv.iloc[8, :]\n",
    "\n",
    "# Add the fourth column to the result DataFrame\n",
    "#result_df['Fourth Column'] = fourth_column\n",
    "\n",
    "path1 = \"G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\ECB projections\\\\\"\n",
    "kk = 'p'\n",
    "\n",
    "for j in range(-1,3):\n",
    "    \n",
    "    queue = f\"Quarter_{j if j >= 0 else 'p'}\"\n",
    "    \n",
    "    #Loop begins here\n",
    "    #Taking the following n forecasts\n",
    "    result_df[queue] = result_df['Quarter'].apply(lambda x: x + j)\n",
    "    #result_df['Next Quarter2'] = result_df['Quarter'].apply(lambda x: x + 2)\n",
    "\n",
    "    result_df[queue] = pd.PeriodIndex(result_df[queue]).strftime('Q%q %Y')\n",
    "\n",
    "#     #Getting indexes where the quarters change\n",
    "#     idlist = result_df.index[result_df['Quarter'].ne(result_df['Quarter'].shift().bfill())].tolist()\n",
    "#     #Adding zero\n",
    "#     idlist.insert(0,0)\n",
    "    \n",
    "    count=0\n",
    "    for var in [rdp, cip]:\n",
    "        \n",
    "        if count == 0: name = 'RealGDP'\n",
    "        if count == 1: name = 'HCIP'\n",
    "        count+=1\n",
    "        # Print the resulting DataFrame\n",
    "#         csvfile_path = path1 + f\"{var}.csv\"\n",
    "#         pd.read_csv(csvfile_path, header=0, skiprows = lambda x: x in range(6))\n",
    "         #Selecting only the target quarter to be replaced in result_df\n",
    "\n",
    "        auxres = result_df\n",
    "        #aux1 = auxres['date']\n",
    "        #aux1 = aux1.apply(find_closest_date)\n",
    "        #result_df['Close'] = auxres['date'].apply(find_closest_date)\n",
    "        \n",
    "        def klug(x):\n",
    "            y1 = x[0] #find closest date -> row a\n",
    "            y2 = x[1]\n",
    "\n",
    "            aux = pd.DataFrame(var['Dates'].apply(lambda x: (x - y1)))\n",
    "            aux1 = aux[aux['Dates']<datetime.timedelta(days=0)]\n",
    "\n",
    "            if aux1.empty:\n",
    "                date_aux = math.nan\n",
    "                var_aux = math.nan\n",
    "                revision_aux = math.nan\n",
    "            else:\n",
    "                indx = aux1.idxmax()\n",
    "                date_aux = var.loc[indx,'Dates'].squeeze()\n",
    "\n",
    "                #The value of the forecast at the given horizon\n",
    "                var_aux = float(var.loc[indx,y2].squeeze())\n",
    "\n",
    "\n",
    "                #Cmputing second dataframe to get revisions\n",
    "                aux2 = aux[aux['Dates']< aux.loc[indx, 'Dates'].squeeze()]\n",
    "\n",
    "                if aux2.empty:\n",
    "                    revision_aux = math.nan\n",
    "                else:    \n",
    "                    indx2 = aux2.idxmax() \n",
    "                    revision_aux = float(var.loc[indx2,y2].squeeze())\n",
    "\n",
    "            return date_aux, var_aux, revision_aux \n",
    "        #Unpacking date and the forecast value\n",
    "        auxi = pd.DataFrame(auxres[['date', queue]].apply(klug, axis=1).to_list(), index=auxres.index)\n",
    "\n",
    "        #result_df.loc[auxres.index,f\"Closest_date_{j if j >= 0 else 'p'}\"] = auxi[0]\n",
    "        result_df.loc[auxres.index,f\"{name}_{j if j >= 0 else 'p'}\"] = auxi[1]\n",
    "        result_df.loc[auxres.index,f\"{name}_Rev_{j if j >= 0 else 'p'}\"] = auxi[1] - auxi[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f716e393",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Now getting unemploment\n",
    "\n",
    "#Adding the year column\n",
    "result_df['Year'] = pd.PeriodIndex(result_df['date'], freq='Y')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "kk = 'p'\n",
    "\n",
    "for j in range(-1,3):\n",
    "    \n",
    "    queue = f\"Year_{j if j >= 0 else 'p'}\"\n",
    "    \n",
    "    #Loop begins here\n",
    "    #Taking the following n forecasts\n",
    "    result_df[queue] = result_df['Year'].apply(lambda x: x + j)\n",
    "    #result_df['Next Quarter2'] = result_df['Quarter'].apply(lambda x: x + 2)\n",
    "\n",
    "\n",
    "    #Getting indexes where the quarters change\n",
    "    idlist = result_df.index[result_df['Quarter'].ne(result_df['Quarter'].shift().bfill())].tolist()\n",
    "    #Adding zero\n",
    "    idlist.insert(0,0)\n",
    "    \n",
    "\n",
    "    for var in [unemp]:\n",
    "        \n",
    "        name = 'Unemployment'\n",
    "        # Print the resulting DataFrame\n",
    "#         csvfile_path = path1 + f\"{var}.csv\"\n",
    "#         pd.read_csv(csvfile_path, header=0, skiprows = lambda x: x in range(6))\n",
    "         #Selecting only the target quarter to be replaced in result_df\n",
    "\n",
    "        auxres = result_df\n",
    "        #aux1 = auxres['date']\n",
    "        #aux1 = aux1.apply(find_closest_date)\n",
    "        #result_df['Close'] = auxres['date'].apply(find_closest_date)\n",
    "        \n",
    "        def klug(x):\n",
    "            y1 = x[0] #find closest date -> row a\n",
    "            y2 = str(x[1])\n",
    "\n",
    "            aux = pd.DataFrame(var['Dates'].apply(lambda x: (x - y1)))\n",
    "            aux1 = aux[aux['Dates']<datetime.timedelta(days=0)]\n",
    "\n",
    "            if aux1.empty:\n",
    "                date_aux = math.nan\n",
    "                var_aux = math.nan\n",
    "                revision_aux = math.nan\n",
    "            else:\n",
    "                indx = aux1.idxmax()\n",
    "                date_aux = var.loc[indx,'Dates'].squeeze()\n",
    "\n",
    "                #The value of the forecast at the given horizon\n",
    "                var_aux = float(var.loc[indx,y2].squeeze())\n",
    "\n",
    "\n",
    "                #Cmputing second dataframe to get revisions\n",
    "                aux2 = aux[aux['Dates']< aux.loc[indx, 'Dates'].squeeze()]\n",
    "\n",
    "                if aux2.empty:\n",
    "                    revision_aux = math.nan\n",
    "                else:    \n",
    "                    indx2 = aux2.idxmax() \n",
    "                    revision_aux = float(var.loc[indx2,y2].squeeze())\n",
    "\n",
    "            return date_aux, var_aux, revision_aux \n",
    "        #Unpacking date and the forecast value\n",
    "        auxi = pd.DataFrame(auxres[['date', queue]].apply(klug, axis=1).to_list(), index=auxres.index)\n",
    "\n",
    "        #result_df.loc[auxres.index,f\"Closest_date_{j if j >= 0 else 'p'}\"] = auxi[0]\n",
    "        result_df.loc[auxres.index,f\"{name}_{j if j >= 0 else 'p'}\"] = auxi[1]\n",
    "        result_df.loc[auxres.index,f\"{name}_Rev_{j if j >= 0 else 'p'}\"] = auxi[1] - auxi[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54bf815e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.iloc[8:,:].isnull().values.any()\n",
    "#From 8th obs there are no nan's left (excluding +2 periods forecast for unemployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "03604c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "variables = ['HCIP', 'Unemployment', 'RealGDP']\n",
    "und = ['_', '_Rev_']\n",
    "index = [0,1,2,'p']\n",
    "forecasts = result_df[[f\"{v}{u}{i}\" for v,u,i in itertools.product(variables, und, index) if not ((v=='Unemployment') and ((i in [2, 1, 'p']) and (u != '_Rev_')))]]\n",
    "forecasts = forecasts.loc[:, forecasts.columns!='Unemployment_Rev_2']\n",
    "forecasts.to_csv(path1+'forecasts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a9cf2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HCIP_2</th>\n",
       "      <th>HCIP_p</th>\n",
       "      <th>HCIP_Rev_0</th>\n",
       "      <th>HCIP_Rev_1</th>\n",
       "      <th>HCIP_Rev_2</th>\n",
       "      <th>HCIP_Rev_p</th>\n",
       "      <th>Unemployment_0</th>\n",
       "      <th>Unemployment_Rev_0</th>\n",
       "      <th>Unemployment_Rev_1</th>\n",
       "      <th>Unemployment_Rev_p</th>\n",
       "      <th>RealGDP_0</th>\n",
       "      <th>RealGDP_1</th>\n",
       "      <th>RealGDP_2</th>\n",
       "      <th>RealGDP_p</th>\n",
       "      <th>RealGDP_Rev_0</th>\n",
       "      <th>RealGDP_Rev_1</th>\n",
       "      <th>RealGDP_Rev_2</th>\n",
       "      <th>RealGDP_Rev_p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>6.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>4.7</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>6.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>291 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     HCIP_2  HCIP_p  HCIP_Rev_0  HCIP_Rev_1  HCIP_Rev_2  HCIP_Rev_p   \n",
       "0       NaN     NaN         NaN         NaN         NaN         NaN  \\\n",
       "1       NaN     NaN         NaN         NaN         NaN         NaN   \n",
       "2       0.9     0.9         NaN         NaN         NaN         NaN   \n",
       "3       0.9     0.9         NaN         NaN         NaN         NaN   \n",
       "4       0.9     0.9         NaN         NaN         NaN         NaN   \n",
       "..      ...     ...         ...         ...         ...         ...   \n",
       "286     4.0     5.6         1.9         2.2         2.1         1.5   \n",
       "287     6.4     6.1         1.9         2.1         2.4         0.5   \n",
       "288     4.7     7.5         2.1         2.4         2.2         1.9   \n",
       "289     8.0     8.0         1.8         2.8         3.3         0.5   \n",
       "290     6.3     9.1         2.8         3.3         2.8         1.8   \n",
       "\n",
       "     Unemployment_0  Unemployment_Rev_0  Unemployment_Rev_1   \n",
       "0               NaN                 NaN                 NaN  \\\n",
       "1               NaN                 NaN                 NaN   \n",
       "2              10.6                 NaN                 NaN   \n",
       "3              10.6                 NaN                 NaN   \n",
       "4              10.6                 NaN                 NaN   \n",
       "..              ...                 ...                 ...   \n",
       "286             7.3                 0.0                 0.3   \n",
       "287             6.8                -0.5                -0.4   \n",
       "288             6.8                -0.5                -0.4   \n",
       "289             6.7                -0.1                 0.1   \n",
       "290             6.7                -0.1                 0.1   \n",
       "\n",
       "     Unemployment_Rev_p  RealGDP_0  RealGDP_1  RealGDP_2  RealGDP_p   \n",
       "0                   NaN        NaN        NaN        NaN        NaN  \\\n",
       "1                   NaN        NaN        NaN        NaN        NaN   \n",
       "2                   NaN        0.5        0.5        0.5        0.5   \n",
       "3                   NaN        0.5        0.5        0.5        0.5   \n",
       "4                   NaN        0.5        0.5        0.5        0.5   \n",
       "..                  ...        ...        ...        ...        ...   \n",
       "286                 0.0        1.0        1.0        0.8        0.2   \n",
       "287                 0.0        0.2        0.4        0.5        0.3   \n",
       "288                 0.0        0.4        0.5        0.6        0.2   \n",
       "289                 0.0        0.1       -0.1        0.0        0.7   \n",
       "290                 0.0       -0.1        0.0        0.4        0.1   \n",
       "\n",
       "     RealGDP_Rev_0  RealGDP_Rev_1  RealGDP_Rev_2  RealGDP_Rev_p  \n",
       "0              NaN            NaN            NaN            NaN  \n",
       "1              NaN            NaN            NaN            NaN  \n",
       "2              NaN            NaN            NaN            NaN  \n",
       "3              NaN            NaN            NaN            NaN  \n",
       "4              NaN            NaN            NaN            NaN  \n",
       "..             ...            ...            ...            ...  \n",
       "286           -0.4           -0.2            0.1           -0.2  \n",
       "287           -0.8           -0.6           -0.3            0.1  \n",
       "288           -0.6           -0.3           -0.1           -0.8  \n",
       "289           -0.3           -0.6           -0.6            0.5  \n",
       "290           -0.6           -0.6           -0.2           -0.3  \n",
       "\n",
       "[291 rows x 18 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts[[v for v in forecasts.columns if v not in ['HCIP_0', 'HCIP_1']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa528c",
   "metadata": {},
   "source": [
    "# Computing instruments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b4fc5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d2590df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Loading dataframes\n",
    "source_file = 'G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\Instrument\\\\Dataset_EA-MPD.xlsx'\n",
    "df_source = pd.read_excel(source_file, header=0, sheet_name=1)\n",
    "\n",
    "path1 = \"G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\ECB projections\\\\\"\n",
    "forecasts = pd.read_csv((path1+'forecasts.csv'), header=0, index_col=0)\n",
    "#forecasts = result_df\n",
    "\n",
    "# Get the reference dates from the first column\n",
    "reference_dates = df_source.iloc[:, 0]\n",
    "\n",
    "# Create a DataFrame with the reference dates\n",
    "result_df = pd.DataFrame(data=reference_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bb05bf0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "variables = ['HCIP', 'Unemployment', 'RealGDP']\n",
    "und = ['_', '_Rev_']\n",
    "index = [0,1,2,'p']\n",
    "forecasts = result_df[[f\"{v}{u}{i}\" for v,u,i in itertools.product(variables, und, index) if not ((v=='Unemployment') and ((i in [2, 1, 'p']) and (u != '_Rev_')))]]\n",
    "\n",
    "forecasts = forecasts.loc[:, forecasts.columns!='Unemployment_Rev_2']\n",
    "#forecasts.to_csv(path1+'forecasts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20d81b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HCIP_0               NaN\n",
       "HCIP_1               NaN\n",
       "HCIP_2               NaN\n",
       "HCIP_p               NaN\n",
       "HCIP_Rev_0           NaN\n",
       "HCIP_Rev_1           NaN\n",
       "HCIP_Rev_2           NaN\n",
       "HCIP_Rev_p           NaN\n",
       "Unemployment_0       NaN\n",
       "Unemployment_Rev_0   NaN\n",
       "Unemployment_Rev_1   NaN\n",
       "Unemployment_Rev_p   NaN\n",
       "RealGDP_0            NaN\n",
       "RealGDP_1            NaN\n",
       "RealGDP_2            NaN\n",
       "RealGDP_p            NaN\n",
       "RealGDP_Rev_0        NaN\n",
       "RealGDP_Rev_1        NaN\n",
       "RealGDP_Rev_2        NaN\n",
       "RealGDP_Rev_p        NaN\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "853dc75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_values_by_month(df):\n",
    "    # Convert the month column to datetime type\n",
    "    #df['Month'] = pd.to_datetime(df['Month'])\n",
    "    \n",
    "    #df = df.groupby('Month')['Values'].sum().reset_index()\n",
    "\n",
    "    \n",
    "    # Create a new dataframe with a complete range of months\n",
    "    min_month = df['Month'].min().to_timestamp()\n",
    "    max_month = df['Month'].max().to_timestamp() + datetime.timedelta(days=32)\n",
    "    complete_months = pd.date_range(start=min_month, end=max_month, freq='M')\n",
    "    complete_df = pd.DataFrame({'Month': complete_months})\n",
    "    \n",
    "    complete_df['Month'] = pd.PeriodIndex(complete_df['Month'], freq='M')\n",
    "    # Merge the original dataframe with the complete dataframe to fill missing months with NaN values\n",
    "    merged_df = pd.merge(complete_df, df, on='Month', how='left')\n",
    "\n",
    "    # Group the merged dataframe by month and calculate the sum of values for each month\n",
    "    #result = merged_df.groupby('Month')['Values'].sum().reset_index()\n",
    "    \n",
    "    result = merged_df\n",
    "    # Fill NaN values with 0\n",
    "    result['Values'] = result['Values'].fillna(0)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27b351c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop version\n",
    "source_file = 'G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\Instrument\\\\Dataset_EA-MPD.xlsx'\n",
    "\n",
    "path3 = \"G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\ECB projections\\\\Instruments\\\\\"\n",
    "df_source = pd.read_excel(source_file, header=0, sheet_name=1)\n",
    "\n",
    "\n",
    "#Period a = initial month/year index, b final month/year index\n",
    "a = 71\n",
    "b = 268 # Nocovid\n",
    "\n",
    "for k in ['SW', '1M', '3M', '6M', '1Y', '2Y']:\n",
    "\n",
    "    y = df_source[f\"OIS_{k}\"][a:b]\n",
    "    x = forecasts.iloc[a:b,:]\n",
    "    #add constant to predictor variables\n",
    "    x = sm.add_constant(x)\n",
    "\n",
    "    #fit linear regression model\n",
    "    model = sm.OLS(y, x, missing='drop').fit()\n",
    "\n",
    "\n",
    "    #path3 = \"G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\DATA\\\\\"\n",
    "    instrument = model.resid\n",
    "    # Get the range of indexes to include\n",
    "    #index_range = range(instrument.index.min(), instrument.index.max() + 1)\n",
    "\n",
    "\n",
    "    ##CHECK THIS LINEEEE!!!! WHAT IS IT DOING?\n",
    "    # Reindex the DataFrame with the full index range\n",
    "    #instrument = instrument.reindex(index=range(0,291))\n",
    "\n",
    "    instrument.to_csv(path3+f\"instrument{k}_autcor.csv\")\n",
    "    \n",
    "    resid = pd.DataFrame(instrument, columns=['Values'])\n",
    "    #Adding month mark\n",
    "    result_df['Month'] = pd.PeriodIndex(result_df['date'], freq='M')\n",
    "    \n",
    "    #Adding the month column to the new dataframe\n",
    "    resid['Month'] = result_df.loc[resid['Values'].index, 'Month']\n",
    "    \n",
    "    MPI = resid.groupby('Month')['Values'].sum().reset_index()\n",
    "    \n",
    "    atreg12 = AutoReg(MPI['Values'], lags=12).fit()\n",
    "\n",
    "    realinstrument =  pd.DataFrame(atreg12.resid, columns=['Values'])\n",
    "    realinstrument['Month'] = MPI.loc[12:, 'Month']\n",
    "    realinstrument = sum_values_by_month(realinstrument)\n",
    "    realinstrument.to_csv(path3+f\"instrument{k}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "102a939c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.302585092994046"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0ceed3",
   "metadata": {},
   "source": [
    "# Pure instrument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a0c1e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pure instrument\n",
    "\n",
    "source_file = 'G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\Instrument\\\\Dataset_EA-MPD.xlsx'\n",
    "df_source = pd.read_excel(source_file, header=0, sheet_name=1)\n",
    "\n",
    "# Get the reference dates from the first column\n",
    "reference_dates = df_source.iloc[:, 0]\n",
    "\n",
    "# Create a DataFrame with the reference dates\n",
    "result_df = pd.DataFrame(data=reference_dates)\n",
    "\n",
    "#Loop version\n",
    "\n",
    "#Period a = initial month/year index, b final month/year index\n",
    "a = 71\n",
    "b = 268\n",
    "\n",
    "for k in ['SW', '1M', '3M', '6M', '1Y', '2Y']:\n",
    "\n",
    "    y = df_source[f\"OIS_{k}\"][a:b]\n",
    "    #x = forecasts.iloc[a:,:]\n",
    "    #add constant to predictor variables\n",
    "    #x = sm.add_constant(x)\n",
    "\n",
    "    #fit linear regression model\n",
    "    #model = sm.OLS(y, x, missing='drop').fit()\n",
    "\n",
    "\n",
    "    path3 = \"G:\\\\Other computers\\\\My laptop\\\\Workarea\\\\Research\\\\ThesisII\\\\DATA\\\\Pure Instruments\\\\\"\n",
    "    instrument = y\n",
    "    # Get the range of indexes to include\n",
    "    #index_range = range(instrument.index.min(), instrument.index.max() + 1)\n",
    "\n",
    "\n",
    "    ##CHECK THIS LINEEEE!!!! WHAT IS IT DOING?\n",
    "    # Reindex the DataFrame with the full index range\n",
    "    #instrument = instrument.reindex(index=range(0,291))\n",
    "\n",
    "    #instrument.to_csv(path3+f\"instrument{k}.csv\")\n",
    "    \n",
    "    resid = pd.DataFrame(instrument).rename(columns={f\"OIS_{k}\":'Values'})\n",
    "    #Adding month mark\n",
    "    result_df['Month'] = pd.PeriodIndex(result_df['date'], freq='M')\n",
    "    \n",
    "    #Adding the month column to the new dataframe\n",
    "    resid['Month'] = result_df.loc[resid['Values'].index, 'Month']\n",
    "    \n",
    "    MPI = resid.groupby('Month')['Values'].sum().reset_index()\n",
    "    \n",
    "    #atreg12 = AutoReg(MPI['Values'], lags=12, missing='drop').fit()\n",
    "\n",
    "    #realinstrument =  pd.DataFrame(atreg12.resid, columns=['Values'])\n",
    "    #realinstrument['Month'] = MPI.loc[12:, 'Month']\n",
    "    realinstrument = sum_values_by_month(MPI)\n",
    "    realinstrument.to_csv(path3+f\"realinstrument{k}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "231e3ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HCIP_0               NaN\n",
       "HCIP_1               NaN\n",
       "HCIP_2               NaN\n",
       "HCIP_p               NaN\n",
       "HCIP_Rev_0           NaN\n",
       "HCIP_Rev_1           NaN\n",
       "HCIP_Rev_2           NaN\n",
       "HCIP_Rev_p           NaN\n",
       "Unemployment_0       NaN\n",
       "Unemployment_Rev_0   NaN\n",
       "Unemployment_Rev_1   NaN\n",
       "Unemployment_Rev_p   NaN\n",
       "RealGDP_0            NaN\n",
       "RealGDP_1            NaN\n",
       "RealGDP_2            NaN\n",
       "RealGDP_p            NaN\n",
       "RealGDP_Rev_0        NaN\n",
       "RealGDP_Rev_1        NaN\n",
       "RealGDP_Rev_2        NaN\n",
       "RealGDP_Rev_p        NaN\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecasts.iloc[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "397dffbc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                 OIS_SW   R-squared (uncentered):                   0.082\n",
      "Model:                            OLS   Adj. R-squared (uncentered):             -0.022\n",
      "Method:                 Least Squares   F-statistic:                             0.7894\n",
      "Date:                Fri, 23 Jun 2023   Prob (F-statistic):                       0.724\n",
      "Time:                        21:30:43   Log-Likelihood:                         -472.34\n",
      "No. Observations:                 197   AIC:                                      984.7\n",
      "Df Residuals:                     177   BIC:                                      1050.\n",
      "Df Model:                          20                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "======================================================================================\n",
      "                         coef    std err          t      P>|t|      [0.025      0.975]\n",
      "--------------------------------------------------------------------------------------\n",
      "HCIP_0                 0.7727      1.244      0.621      0.535      -1.681       3.227\n",
      "HCIP_1                -1.6730      1.298     -1.289      0.199      -4.234       0.888\n",
      "HCIP_2                 0.5767      1.086      0.531      0.596      -1.566       2.720\n",
      "HCIP_p                -0.2832      0.872     -0.325      0.746      -2.004       1.437\n",
      "HCIP_Rev_0             0.9562      2.688      0.356      0.722      -4.349       6.262\n",
      "HCIP_Rev_1             2.1823      2.729      0.800      0.425      -3.204       7.568\n",
      "HCIP_Rev_2            -2.1563      2.339     -0.922      0.358      -6.772       2.460\n",
      "HCIP_Rev_p            -0.8548      1.807     -0.473      0.637      -4.421       2.711\n",
      "Unemployment_0         0.0174      0.082      0.211      0.833      -0.145       0.180\n",
      "Unemployment_Rev_0     3.2544      2.963      1.098      0.274      -2.593       9.101\n",
      "Unemployment_Rev_1    -1.1079      2.002     -0.553      0.581      -5.060       2.844\n",
      "Unemployment_Rev_p    -5.1882      2.563     -2.024      0.044     -10.247      -0.130\n",
      "RealGDP_0              1.2740      3.643      0.350      0.727      -5.915       8.463\n",
      "RealGDP_1             -1.9352      4.859     -0.398      0.691     -11.523       7.653\n",
      "RealGDP_2              2.9794      4.097      0.727      0.468      -5.106      11.065\n",
      "RealGDP_p             -0.2206      2.067     -0.107      0.915      -4.300       3.859\n",
      "RealGDP_Rev_0         -2.8581      3.581     -0.798      0.426      -9.926       4.209\n",
      "RealGDP_Rev_1         -1.0795      4.218     -0.256      0.798      -9.404       7.245\n",
      "RealGDP_Rev_2         -1.1904      3.810     -0.312      0.755      -8.709       6.328\n",
      "RealGDP_Rev_p          1.6895      2.435      0.694      0.489      -3.115       6.494\n",
      "==============================================================================\n",
      "Omnibus:                      109.940   Durbin-Watson:                   2.477\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2094.055\n",
      "Skew:                          -1.630   Prob(JB):                         0.00\n",
      "Kurtosis:                      18.636   Cond. No.                         366.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#df_source = df_source.set_index(pd.Series(range(0,291)))\n",
    "#forecasts = forecasts.set_index(pd.Series(range(0,291)))\n",
    "df_source = pd.read_excel(source_file, header=0, sheet_name=3)\n",
    "\n",
    "y = df_source['OIS_SW'][71:268]\n",
    "#x1 = forecasts[[v for v in forecasts.columns if v not in ['Unemployment_Rev_1', 'RealGDP_Rev_2', 'RealGDP_Rev_1','RealGDP_Rev_p', 'RealGDP_p','RealGDP_1','RealGDP_2','HCIP_Rev_p','HCIP_Rev_1', 'HCIP_Rev_2','HCIP_p', 'HCIP_1','HCIP_2']]]\n",
    "#x1 = forecasts[[v for v in forecasts.columns if v not in ['Unemployment_Rev_1','Unemployment_1','Unemployment_2','Unemployment_p', 'Unemployment_Rev_2','HCIP_Rev_2','HCIP_Rev_1','RealGDP_Rev_1','HCIP_0','HCIP_p','RealGDP_2','RealGDP_p','HCIP_Rev_0','Unemployment_0','RealGDP_1','Unemployment_Rev_0','HCIP_Rev_p','RealGDP_Rev_2', 'RealGDP_Rev_0', 'RealGDP_Rev_p', 'RealGDP_0', 'HCIP_1', 'HCIP_2']]]\n",
    "\n",
    "#x = x1.iloc[71:268,:]\n",
    "\n",
    "\n",
    "x = forecasts.iloc[71:268,:]\n",
    "#add constant to predictor variables\n",
    "#x = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x, missing='drop').fit()\n",
    "\n",
    "#view model summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "91a25b1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Test Statistic': 22.678319732495826, 'Test Statistic p-value': 0.06570956172257252, 'F-Statistic': 1.704884174384756, 'F-Test p-value': 0.059670152205849196}\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.diagnostic import het_white\n",
    "#perform White's test\n",
    "white_test = het_white(model.resid,  model.model.exog)\n",
    "\n",
    "#define labels to use for output of White's test\n",
    "labels = ['Test Statistic', 'Test Statistic p-value', 'F-Statistic', 'F-Test p-value']\n",
    "\n",
    "#print results of White's test\n",
    "print(dict(zip(labels, white_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fde81597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2003-01-31', '2003-02-28', '2003-03-31', '2003-04-30',\n",
       "               '2003-05-31', '2003-06-30', '2003-07-31', '2003-08-31',\n",
       "               '2003-09-30', '2003-10-31',\n",
       "               ...\n",
       "               '2022-01-31', '2022-02-28', '2022-03-31', '2022-04-30',\n",
       "               '2022-05-31', '2022-06-30', '2022-07-31', '2022-08-31',\n",
       "               '2022-09-30', '2022-10-31'],\n",
       "              dtype='datetime64[ns]', length=238, freq='M')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_month = realinstrument['Month'].min().to_timestamp()\n",
    "max_month = realinstrument['Month'].max().to_timestamp() \n",
    "complete_months = pd.date_range(start=min_month, end=max_month, freq='M')\n",
    "complete_df = pd.DataFrame({'Month': complete_months})\n",
    "complete_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7fbca33b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-12-01 00:00:00')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "56107412",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class timedelta in module datetime:\n",
      "\n",
      "class timedelta(builtins.object)\n",
      " |  Difference between two datetime values.\n",
      " |  \n",
      " |  timedelta(days=0, seconds=0, microseconds=0, milliseconds=0, minutes=0, hours=0, weeks=0)\n",
      " |  \n",
      " |  All arguments are optional and default to 0.\n",
      " |  Arguments may be integers or floats, and may be positive or negative.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __abs__(self, /)\n",
      " |      abs(self)\n",
      " |  \n",
      " |  __add__(self, value, /)\n",
      " |      Return self+value.\n",
      " |  \n",
      " |  __bool__(self, /)\n",
      " |      True if self else False\n",
      " |  \n",
      " |  __divmod__(self, value, /)\n",
      " |      Return divmod(self, value).\n",
      " |  \n",
      " |  __eq__(self, value, /)\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __floordiv__(self, value, /)\n",
      " |      Return self//value.\n",
      " |  \n",
      " |  __ge__(self, value, /)\n",
      " |      Return self>=value.\n",
      " |  \n",
      " |  __getattribute__(self, name, /)\n",
      " |      Return getattr(self, name).\n",
      " |  \n",
      " |  __gt__(self, value, /)\n",
      " |      Return self>value.\n",
      " |  \n",
      " |  __hash__(self, /)\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __le__(self, value, /)\n",
      " |      Return self<=value.\n",
      " |  \n",
      " |  __lt__(self, value, /)\n",
      " |      Return self<value.\n",
      " |  \n",
      " |  __mod__(self, value, /)\n",
      " |      Return self%value.\n",
      " |  \n",
      " |  __mul__(self, value, /)\n",
      " |      Return self*value.\n",
      " |  \n",
      " |  __ne__(self, value, /)\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  __neg__(self, /)\n",
      " |      -self\n",
      " |  \n",
      " |  __pos__(self, /)\n",
      " |      +self\n",
      " |  \n",
      " |  __radd__(self, value, /)\n",
      " |      Return value+self.\n",
      " |  \n",
      " |  __rdivmod__(self, value, /)\n",
      " |      Return divmod(value, self).\n",
      " |  \n",
      " |  __reduce__(...)\n",
      " |      __reduce__() -> (cls, state)\n",
      " |  \n",
      " |  __repr__(self, /)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __rfloordiv__(self, value, /)\n",
      " |      Return value//self.\n",
      " |  \n",
      " |  __rmod__(self, value, /)\n",
      " |      Return value%self.\n",
      " |  \n",
      " |  __rmul__(self, value, /)\n",
      " |      Return value*self.\n",
      " |  \n",
      " |  __rsub__(self, value, /)\n",
      " |      Return value-self.\n",
      " |  \n",
      " |  __rtruediv__(self, value, /)\n",
      " |      Return value/self.\n",
      " |  \n",
      " |  __str__(self, /)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  __sub__(self, value, /)\n",
      " |      Return self-value.\n",
      " |  \n",
      " |  __truediv__(self, value, /)\n",
      " |      Return self/value.\n",
      " |  \n",
      " |  total_seconds(...)\n",
      " |      Total seconds in the duration.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  days\n",
      " |      Number of days.\n",
      " |  \n",
      " |  microseconds\n",
      " |      Number of microseconds (>= 0 and less than 1 second).\n",
      " |  \n",
      " |  seconds\n",
      " |      Number of seconds (>= 0 and less than 1 day).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  max = datetime.timedelta(days=999999999, seconds=86399, microseconds=9...\n",
      " |  \n",
      " |  min = datetime.timedelta(days=-999999999)\n",
      " |  \n",
      " |  resolution = datetime.timedelta(microseconds=1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(datetime.timedelta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7f0fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7801f70f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2132d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d4f0bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a949d8fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af772c3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d56c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
